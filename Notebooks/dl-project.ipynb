{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-07-08T20:56:28.660270Z","iopub.execute_input":"2022-07-08T20:56:28.660570Z","iopub.status.idle":"2022-07-08T20:56:28.683381Z","shell.execute_reply.started":"2022-07-08T20:56:28.660494Z","shell.execute_reply":"2022-07-08T20:56:28.682607Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## Check Libraires ","metadata":{}},{"cell_type":"code","source":"pip install tensorflow-text==2.6.0-dev20210407\n","metadata":{"execution":{"iopub.status.busy":"2022-07-08T20:05:12.881549Z","iopub.execute_input":"2022-07-08T20:05:12.882359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install --upgrade tensorflow-gpu","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Imports","metadata":{}},{"cell_type":"code","source":"# Imports\nimport cv2\nimport os\nfrom tqdm import tqdm\nfrom glob import glob\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras.utils import np_utils\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\n\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential, Model\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, GlobalAveragePooling2D","metadata":{"execution":{"iopub.status.busy":"2022-07-08T20:56:28.685223Z","iopub.execute_input":"2022-07-08T20:56:28.685549Z","iopub.status.idle":"2022-07-08T20:56:34.885227Z","shell.execute_reply.started":"2022-07-08T20:56:28.685516Z","shell.execute_reply":"2022-07-08T20:56:34.884177Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Loading Dataset","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"../input/state-farm-distracted-driver-detection/driver_imgs_list.csv\")\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T20:56:40.716261Z","iopub.execute_input":"2022-07-08T20:56:40.716636Z","iopub.status.idle":"2022-07-08T20:56:40.745145Z","shell.execute_reply.started":"2022-07-08T20:56:40.716597Z","shell.execute_reply":"2022-07-08T20:56:40.744281Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"  subject classname            img\n0    p002        c0  img_44733.jpg\n1    p002        c0  img_72999.jpg\n2    p002        c0  img_25094.jpg\n3    p002        c0  img_69092.jpg\n4    p002        c0  img_92629.jpg","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subject</th>\n      <th>classname</th>\n      <th>img</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>p002</td>\n      <td>c0</td>\n      <td>img_44733.jpg</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>p002</td>\n      <td>c0</td>\n      <td>img_72999.jpg</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>p002</td>\n      <td>c0</td>\n      <td>img_25094.jpg</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>p002</td>\n      <td>c0</td>\n      <td>img_69092.jpg</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>p002</td>\n      <td>c0</td>\n      <td>img_92629.jpg</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Group bt Drivers/ Test Subjects\nby_drivers = df.groupby('subject')\n\nunique_drivers = by_drivers.groups.keys()\n\nprint(\"There are: \", len(unique_drivers), \" unique drivers\")\nprint('There is a mean of ',round(by_drivers.count()['classname']), ' images by driver.')","metadata":{"execution":{"iopub.status.busy":"2022-07-08T20:56:40.929973Z","iopub.execute_input":"2022-07-08T20:56:40.930598Z","iopub.status.idle":"2022-07-08T20:56:40.955396Z","shell.execute_reply.started":"2022-07-08T20:56:40.930551Z","shell.execute_reply":"2022-07-08T20:56:40.954434Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"There are:  26  unique drivers\nThere is a mean of  subject\np002     725\np012     823\np014     876\np015     875\np016    1078\np021    1237\np022    1233\np024    1226\np026    1196\np035     848\np039     651\np041     605\np042     591\np045     724\np047     835\np049    1011\np050     790\np051     920\np052     740\np056     794\np061     809\np064     820\np066    1034\np072     346\np075     814\np081     823\nName: classname, dtype: int64  images by driver.\n","output_type":"stream"}]},{"cell_type":"code","source":"NUMBER_CLASSES = 10","metadata":{"execution":{"iopub.status.busy":"2022-07-08T20:56:42.267097Z","iopub.execute_input":"2022-07-08T20:56:42.267452Z","iopub.status.idle":"2022-07-08T20:56:42.272346Z","shell.execute_reply.started":"2022-07-08T20:56:42.267425Z","shell.execute_reply":"2022-07-08T20:56:42.271275Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Read with opencv\ndef get_cv2_image(path, img_rows, img_cols, color_type=3):\n    \"\"\"\n    Function that return an opencv image from the path and the right number of dimension\n    \"\"\"\n    if color_type == 1: # Loading as Grayscale image\n        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n    elif color_type == 3: # Loading as color image\n        img = cv2.imread(path, cv2.IMREAD_COLOR)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # Converts to RGB\n\n    img = cv2.resize(img, (img_rows, img_cols)) # Reduce size\n    return img\n\n# Loading Training dataset\ndef load_train(img_rows, img_cols, color_type=3):\n    \"\"\"\n    Return train images and train labels from the original path\n    \"\"\"\n    train_images = [] \n    train_labels = []\n    # Loop over the training folder \n    for classed in tqdm(range(NUMBER_CLASSES)):\n        print('Loading directory c{}'.format(classed))\n        files = glob(os.path.join('../input/state-farm-distracted-driver-detection/imgs/train/c' + str(classed), '*.jpg'))\n        for file in files:\n            img = get_cv2_image(file, img_rows, img_cols, color_type)\n            train_images.append(img)\n            train_labels.append(classed)\n    return train_images, train_labels \n\ndef read_and_normalize_train_data(img_rows, img_cols, color_type):\n    \"\"\"\n    Load + categorical + split\n    \"\"\"\n    X, labels = load_train(img_rows, img_cols, color_type)\n    y = np_utils.to_categorical(labels, 10) #categorical train label\n    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) # split into train and test\n    x_train = np.array(x_train, dtype=np.uint8).reshape(-1,img_rows,img_cols,color_type)\n    x_test = np.array(x_test, dtype=np.uint8).reshape(-1,img_rows,img_cols,color_type)\n    \n    return x_train, x_test, y_train, y_test\n\n# Loading validation dataset\ndef load_test(size=200000, img_rows=64, img_cols=64, color_type=3):\n    \"\"\"\n    Same as above but for validation dataset\n    \"\"\"\n    path = os.path.join('../input/state-farm-distracted-driver-detection/imgs/test', '*.jpg')\n    files = sorted(glob(path))\n    X_test, X_test_id = [], []\n    total = 0\n    files_size = len(files)\n    for file in tqdm(files):\n        if total >= size or total >= files_size:\n            break\n        file_base = os.path.basename(file)\n        img = get_cv2_image(file, img_rows, img_cols, color_type)\n        X_test.append(img)\n        X_test_id.append(file_base)\n        total += 1\n    return X_test, X_test_id\n\ndef read_and_normalize_sampled_test_data(size, img_rows, img_cols, color_type=3):\n    test_data, test_ids = load_test(size, img_rows, img_cols, color_type)   \n    test_data = np.array(test_data, dtype=np.uint8)\n    test_data = test_data.reshape(-1,img_rows,img_cols,color_type)\n    return test_data, test_ids","metadata":{"execution":{"iopub.status.busy":"2022-07-08T20:56:43.950491Z","iopub.execute_input":"2022-07-08T20:56:43.951201Z","iopub.status.idle":"2022-07-08T20:56:43.968010Z","shell.execute_reply.started":"2022-07-08T20:56:43.951166Z","shell.execute_reply":"2022-07-08T20:56:43.967053Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# dimension of images\nimg_rows = 128 \nimg_cols = 128\n\ncolor_type = 1 # grey\nnb_test_samples = 200","metadata":{"execution":{"iopub.status.busy":"2022-07-08T20:56:45.752440Z","iopub.execute_input":"2022-07-08T20:56:45.752951Z","iopub.status.idle":"2022-07-08T20:56:45.758854Z","shell.execute_reply.started":"2022-07-08T20:56:45.752908Z","shell.execute_reply":"2022-07-08T20:56:45.757891Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# loading train images\nx_train, x_test, y_train, y_test = read_and_normalize_train_data(img_rows, img_cols, color_type)\n\n# loading validation images\ntest_files, test_targets = read_and_normalize_sampled_test_data(nb_test_samples, img_rows, img_cols, color_type)","metadata":{"execution":{"iopub.status.busy":"2022-07-08T20:56:47.021769Z","iopub.execute_input":"2022-07-08T20:56:47.022723Z","iopub.status.idle":"2022-07-08T20:59:32.464610Z","shell.execute_reply.started":"2022-07-08T20:56:47.022680Z","shell.execute_reply":"2022-07-08T20:59:32.462900Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"  0%|          | 0/10 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Loading directory c0\n","output_type":"stream"},{"name":"stderr","text":" 10%|█         | 1/10 [00:18<02:44, 18.27s/it]","output_type":"stream"},{"name":"stdout","text":"Loading directory c1\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 2/10 [00:34<02:16, 17.05s/it]","output_type":"stream"},{"name":"stdout","text":"Loading directory c2\n","output_type":"stream"},{"name":"stderr","text":" 30%|███       | 3/10 [00:51<02:00, 17.21s/it]","output_type":"stream"},{"name":"stdout","text":"Loading directory c3\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 4/10 [01:08<01:42, 17.05s/it]","output_type":"stream"},{"name":"stdout","text":"Loading directory c4\n","output_type":"stream"},{"name":"stderr","text":" 50%|█████     | 5/10 [01:25<01:24, 16.88s/it]","output_type":"stream"},{"name":"stdout","text":"Loading directory c5\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 6/10 [01:41<01:07, 16.80s/it]","output_type":"stream"},{"name":"stdout","text":"Loading directory c6\n","output_type":"stream"},{"name":"stderr","text":" 70%|███████   | 7/10 [01:58<00:50, 16.76s/it]","output_type":"stream"},{"name":"stdout","text":"Loading directory c7\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 8/10 [02:13<00:32, 16.02s/it]","output_type":"stream"},{"name":"stdout","text":"Loading directory c8\n","output_type":"stream"},{"name":"stderr","text":" 90%|█████████ | 9/10 [02:26<00:15, 15.36s/it]","output_type":"stream"},{"name":"stdout","text":"Loading directory c9\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [02:42<00:00, 16.22s/it]\n  0%|          | 200/79726 [00:01<10:03, 131.74it/s]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## EDA","metadata":{}},{"cell_type":"code","source":"x_train_size = len(x_train)\nx_test_size = len(x_test)\ntest_files_size = len(np.array(glob(os.path.join('../input/state-farm-distracted-driver-detection/imgs/test', '*.jpg'))))","metadata":{"execution":{"iopub.status.busy":"2022-07-08T21:01:50.565879Z","iopub.execute_input":"2022-07-08T21:01:50.566821Z","iopub.status.idle":"2022-07-08T21:01:50.861836Z","shell.execute_reply.started":"2022-07-08T21:01:50.566784Z","shell.execute_reply":"2022-07-08T21:01:50.860860Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"> ## Statistical numbers about the data","metadata":{}},{"cell_type":"code","source":"print('There are %s total images.' %(x_train_size + x_test_size + test_files_size))\nprint('There are %d total training categories.' %NUMBER_CLASSES )\nprint('There are %d training images.' % x_train_size)\nprint('There are %d validation images.' % x_test_size)\nprint('There are %d test images.'% test_files_size)","metadata":{"execution":{"iopub.status.busy":"2022-07-08T21:02:04.264479Z","iopub.execute_input":"2022-07-08T21:02:04.265090Z","iopub.status.idle":"2022-07-08T21:02:04.270947Z","shell.execute_reply.started":"2022-07-08T21:02:04.265054Z","shell.execute_reply":"2022-07-08T21:02:04.269979Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"There are 102150 total images.\nThere are 10 total training categories.\nThere are 17939 training images.\nThere are 4485 validation images.\nThere are 79726 test images.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"> ## Data Visualization","metadata":{}},{"cell_type":"code","source":"import plotly.express as px\n\npx.histogram(df, x=\"classname\", color=\"classname\", title=\"Number of images by categories \")","metadata":{"execution":{"iopub.status.busy":"2022-07-08T20:20:12.185356Z","iopub.execute_input":"2022-07-08T20:20:12.186062Z","iopub.status.idle":"2022-07-08T20:20:15.626984Z","shell.execute_reply.started":"2022-07-08T20:20:12.186026Z","shell.execute_reply":"2022-07-08T20:20:15.626154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Number of Images by Drivers / Test Subject","metadata":{"execution":{"iopub.status.busy":"2022-07-08T20:20:15.627987Z","iopub.execute_input":"2022-07-08T20:20:15.628308Z","iopub.status.idle":"2022-07-08T20:20:15.634306Z","shell.execute_reply.started":"2022-07-08T20:20:15.628276Z","shell.execute_reply":"2022-07-08T20:20:15.633224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# np.save('./x_train.npy',x_train)\n# np.save('./y_train.npy',y_train)\n# np.save('./x_test.npy',x_test)\n# np.save('./y_test.npy',y_test)","metadata":{"execution":{"iopub.status.busy":"2022-07-08T20:20:15.636055Z","iopub.execute_input":"2022-07-08T20:20:15.636444Z","iopub.status.idle":"2022-07-08T20:20:15.644016Z","shell.execute_reply.started":"2022-07-08T20:20:15.636344Z","shell.execute_reply":"2022-07-08T20:20:15.643052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Fully connected layer","metadata":{}},{"cell_type":"markdown","source":"## Fill this to continue running smoothly, I think","metadata":{}},{"cell_type":"code","source":"# x_train = np.load('../input/dl-project/x_train.npy').astype('float32')/255\n# y_train = np_utils.to_categorical(np.load('../input/dl-project/y_train.npy'))\n# x_val = np.load('../input/dl-project/x_test.npy').astype('float32')/255\n# y_val = np_utils.to_categorical(np.load('../input/dl-project/y_test.npy'))\nno_epoch = 5\nbatch_size = 64\nimg_height = img_rows\nimg_width = img_cols\nchannels = 1","metadata":{"execution":{"iopub.status.busy":"2022-07-08T20:31:41.767485Z","iopub.execute_input":"2022-07-08T20:31:41.767824Z","iopub.status.idle":"2022-07-08T20:31:41.774342Z","shell.execute_reply.started":"2022-07-08T20:31:41.76779Z","shell.execute_reply":"2022-07-08T20:31:41.773362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# x_train = tf.convert_to_tensor(x_train, dtype=tf.float32)/255\n# y_train = tf.convert_to_tensor(y_train, dtype=tf.float32)\n# x_val = tf.convert_to_tensor(x_val, dtype=tf.float32)/255\n# y_val = tf.convert_to_tensor(y_val, dtype=tf.float32)","metadata":{"execution":{"iopub.status.busy":"2022-07-08T20:20:15.655068Z","iopub.execute_input":"2022-07-08T20:20:15.65602Z","iopub.status.idle":"2022-07-08T20:20:15.660941Z","shell.execute_reply.started":"2022-07-08T20:20:15.655986Z","shell.execute_reply":"2022-07-08T20:20:15.659551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Building initial model","metadata":{}},{"cell_type":"code","source":"# temp\nx_train_FC = x_train.reshape((x_train_size, img_rows*img_cols*1))\nx_train_FC = x_train_FC.astype('float32')/255\nx_val_FC = x_test.reshape((x_test_size, img_rows*img_cols*1))\nx_val_FC = x_val_FC.astype('float32')/255\ny_val = y_test","metadata":{"execution":{"iopub.status.busy":"2022-07-08T20:20:15.662981Z","iopub.execute_input":"2022-07-08T20:20:15.663963Z","iopub.status.idle":"2022-07-08T20:20:16.156525Z","shell.execute_reply.started":"2022-07-08T20:20:15.663923Z","shell.execute_reply":"2022-07-08T20:20:16.15554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FC_init = Sequential()\n# FC_init.add(Flatten())\nFC_init.add(Dense(512, activation='relu', name='Layer_1', input_shape=(img_width * img_height * channels,)))\nFC_init.add(Dense(256, activation='relu', name='Layer_2'))\nFC_init.add(Dense(128, activation='relu', name='Layer_3'))\nFC_init.add(Dense(10, activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2022-07-08T20:20:16.159943Z","iopub.execute_input":"2022-07-08T20:20:16.160409Z","iopub.status.idle":"2022-07-08T20:20:18.661934Z","shell.execute_reply.started":"2022-07-08T20:20:16.160367Z","shell.execute_reply":"2022-07-08T20:20:18.660943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"opt = keras.optimizers.Adam(learning_rate=10e-3)\nFC_init.compile(optimizer=opt,\n                loss='categorical_crossentropy',\n                metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-07-08T20:20:18.663303Z","iopub.execute_input":"2022-07-08T20:20:18.664118Z","iopub.status.idle":"2022-07-08T20:20:19.010954Z","shell.execute_reply.started":"2022-07-08T20:20:18.664077Z","shell.execute_reply":"2022-07-08T20:20:19.010061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FC_init.summary()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T20:20:19.012305Z","iopub.execute_input":"2022-07-08T20:20:19.01283Z","iopub.status.idle":"2022-07-08T20:20:19.021952Z","shell.execute_reply.started":"2022-07-08T20:20:19.012777Z","shell.execute_reply":"2022-07-08T20:20:19.020066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"early_stopping = keras.callbacks.EarlyStopping(\n    monitor='val_loss',\n    min_delta=0,\n    patience=2,\n    verbose=1,\n    mode='min',\n    baseline=None,\n    restore_best_weights=True\n)","metadata":{"execution":{"iopub.status.busy":"2022-07-08T20:20:19.023818Z","iopub.execute_input":"2022-07-08T20:20:19.024164Z","iopub.status.idle":"2022-07-08T20:20:19.035256Z","shell.execute_reply.started":"2022-07-08T20:20:19.024128Z","shell.execute_reply":"2022-07-08T20:20:19.034226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"History = FC_init.fit(x_train_FC,y_train, validation_data=(x_val_FC,y_val), verbose = 1, epochs = no_epoch, batch_size = batch_size,callbacks=[early_stopping])","metadata":{"execution":{"iopub.status.busy":"2022-07-08T20:20:19.036899Z","iopub.execute_input":"2022-07-08T20:20:19.037239Z","iopub.status.idle":"2022-07-08T20:20:31.254565Z","shell.execute_reply.started":"2022-07-08T20:20:19.037204Z","shell.execute_reply":"2022-07-08T20:20:31.253596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc = History.history['accuracy']\nval_acc = History.history['val_accuracy']\nloss = History.history['loss']\nval_loss = History.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\n\nplt.figure()\n\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T20:20:31.257379Z","iopub.execute_input":"2022-07-08T20:20:31.257859Z","iopub.status.idle":"2022-07-08T20:20:31.654529Z","shell.execute_reply.started":"2022-07-08T20:20:31.257819Z","shell.execute_reply":"2022-07-08T20:20:31.653781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Predict ","metadata":{}},{"cell_type":"code","source":"test_files.dtype","metadata":{"execution":{"iopub.status.busy":"2022-07-08T20:12:58.728673Z","iopub.execute_input":"2022-07-08T20:12:58.729022Z","iopub.status.idle":"2022-07-08T20:12:58.735998Z","shell.execute_reply.started":"2022-07-08T20:12:58.728986Z","shell.execute_reply":"2022-07-08T20:12:58.73484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_files[0].shape","metadata":{"execution":{"iopub.status.busy":"2022-07-08T12:46:27.333886Z","iopub.execute_input":"2022-07-08T12:46:27.334731Z","iopub.status.idle":"2022-07-08T12:46:27.343738Z","shell.execute_reply.started":"2022-07-08T12:46:27.334695Z","shell.execute_reply":"2022-07-08T12:46:27.342605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train.dtype","metadata":{"execution":{"iopub.status.busy":"2022-07-08T12:46:27.345465Z","iopub.execute_input":"2022-07-08T12:46:27.346254Z","iopub.status.idle":"2022-07-08T12:46:27.353407Z","shell.execute_reply.started":"2022-07-08T12:46:27.346076Z","shell.execute_reply":"2022-07-08T12:46:27.352301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(test_files))\nprint(test_files_size)\n","metadata":{"execution":{"iopub.status.busy":"2022-07-08T12:46:27.356386Z","iopub.execute_input":"2022-07-08T12:46:27.356662Z","iopub.status.idle":"2022-07-08T12:46:27.362651Z","shell.execute_reply.started":"2022-07-08T12:46:27.356638Z","shell.execute_reply":"2022-07-08T12:46:27.361465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_imgs = test_files.reshape((nb_test_samples, img_rows*img_cols*1))\ntest_imgs = test_imgs.astype('float32')/255\n","metadata":{"execution":{"iopub.status.busy":"2022-07-08T12:46:27.364095Z","iopub.execute_input":"2022-07-08T12:46:27.364778Z","iopub.status.idle":"2022-07-08T12:46:27.374502Z","shell.execute_reply.started":"2022-07-08T12:46:27.36467Z","shell.execute_reply":"2022-07-08T12:46:27.373302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = FC_init.predict(test_imgs)\npred[0]","metadata":{"execution":{"iopub.status.busy":"2022-07-08T12:46:27.376224Z","iopub.execute_input":"2022-07-08T12:46:27.376865Z","iopub.status.idle":"2022-07-08T12:46:27.814157Z","shell.execute_reply.started":"2022-07-08T12:46:27.376827Z","shell.execute_reply":"2022-07-08T12:46:27.813252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FC_init.evaluate(test_imgs, pred)","metadata":{"execution":{"iopub.status.busy":"2022-07-08T12:46:27.815533Z","iopub.execute_input":"2022-07-08T12:46:27.815886Z","iopub.status.idle":"2022-07-08T12:46:27.914182Z","shell.execute_reply.started":"2022-07-08T12:46:27.81585Z","shell.execute_reply":"2022-07-08T12:46:27.913286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Evaluate the model","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Building Baseline CNN Model","metadata":{}},{"cell_type":"code","source":"# temp\nx_train_CNN = x_train.reshape((x_train_size, img_rows,img_cols,1))\nx_train_CNN = x_train_CNN.astype('float32')/255\nx_val_CNN = x_test.reshape((x_test_size, img_rows,img_cols,1))\nx_val_CNN = x_val_CNN.astype('float32')/255\ny_val = y_test","metadata":{"execution":{"iopub.status.busy":"2022-07-08T20:20:47.331453Z","iopub.execute_input":"2022-07-08T20:20:47.332067Z","iopub.status.idle":"2022-07-08T20:20:47.826938Z","shell.execute_reply.started":"2022-07-08T20:20:47.332033Z","shell.execute_reply":"2022-07-08T20:20:47.825923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CNN_model = Sequential()\nCNN_model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, channels)))\nCNN_model.add(MaxPooling2D((2, 2)))\nCNN_model.add(Conv2D(64, (3, 3), activation='relu'))\nCNN_model.add(MaxPooling2D((2, 2)))\nCNN_model.add(Conv2D(64, (3, 3), activation='relu'))\nCNN_model.add(Flatten())\nCNN_model.add(Dense(64, activation='relu'))\nCNN_model.add(Dense(10, activation='softmax'))\n","metadata":{"execution":{"iopub.status.busy":"2022-07-08T20:20:48.05594Z","iopub.execute_input":"2022-07-08T20:20:48.056243Z","iopub.status.idle":"2022-07-08T20:20:48.117258Z","shell.execute_reply.started":"2022-07-08T20:20:48.056215Z","shell.execute_reply":"2022-07-08T20:20:48.116437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"adam = tf.keras.optimizers.Adam(learning_rate=0.0001)\nCNN_model.compile(optimizer=\"rmsprop\",\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-07-08T20:20:49.925772Z","iopub.execute_input":"2022-07-08T20:20:49.926639Z","iopub.status.idle":"2022-07-08T20:20:49.939043Z","shell.execute_reply.started":"2022-07-08T20:20:49.92659Z","shell.execute_reply":"2022-07-08T20:20:49.937969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CNN_model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T20:20:51.487852Z","iopub.execute_input":"2022-07-08T20:20:51.488397Z","iopub.status.idle":"2022-07-08T20:20:51.496298Z","shell.execute_reply.started":"2022-07-08T20:20:51.488358Z","shell.execute_reply":"2022-07-08T20:20:51.49474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"History_CNN = CNN_model.fit(x_train_CNN,y_train, validation_data=(x_val_CNN,y_val), verbose = 1, epochs = no_epoch, batch_size = batch_size,callbacks=[early_stopping])","metadata":{"execution":{"iopub.status.busy":"2022-07-08T20:20:53.484293Z","iopub.execute_input":"2022-07-08T20:20:53.484627Z","iopub.status.idle":"2022-07-08T20:21:23.809346Z","shell.execute_reply.started":"2022-07-08T20:20:53.484598Z","shell.execute_reply":"2022-07-08T20:21:23.808416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc = History_CNN.history['accuracy']\nval_acc = History_CNN.history['val_accuracy']\nloss = History_CNN.history['loss']\nval_loss = History_CNN.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\n\nplt.figure()\n\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T20:21:23.811407Z","iopub.execute_input":"2022-07-08T20:21:23.81179Z","iopub.status.idle":"2022-07-08T20:21:24.174314Z","shell.execute_reply.started":"2022-07-08T20:21:23.811751Z","shell.execute_reply":"2022-07-08T20:21:24.173411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_imgs = test_files.reshape((nb_test_samples, img_rows,img_cols,1))\ntest_imgs = test_imgs.astype('float32')/255\n","metadata":{"execution":{"iopub.status.busy":"2022-07-08T20:13:43.519035Z","iopub.execute_input":"2022-07-08T20:13:43.519338Z","iopub.status.idle":"2022-07-08T20:13:43.52748Z","shell.execute_reply.started":"2022-07-08T20:13:43.519312Z","shell.execute_reply":"2022-07-08T20:13:43.526287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = CNN_model.predict(test_imgs)\npred[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Augmentation","metadata":{}},{"cell_type":"code","source":"Traindatagen = ImageDataGenerator(\n      featurewise_center = True,\n      featurewise_std_normalization = True,\n      rescale = 1.0/255,\n      rotation_range=40,\n      width_shift_range=0.2,\n      height_shift_range=0.2,\n      shear_range=0.2,\n      zoom_range=0.2,\n      horizontal_flip=True,\n      vertical_flip=False,\n      fill_mode='nearest')\n\n\nValdatagen =  ImageDataGenerator(featurewise_center = True, \n                                 featurewise_std_normalization = True, \n                                 rescale=1.0/ 255, \n                                 validation_split = 0.2)","metadata":{"execution":{"iopub.status.busy":"2022-07-08T21:02:37.841178Z","iopub.execute_input":"2022-07-08T21:02:37.841663Z","iopub.status.idle":"2022-07-08T21:02:37.849818Z","shell.execute_reply.started":"2022-07-08T21:02:37.841620Z","shell.execute_reply":"2022-07-08T21:02:37.848857Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# Transfer learning using VGG16","metadata":{}},{"cell_type":"code","source":"# loading train images\nx_train_vgg, x_test_vgg, y_train_vgg, y_test_vgg = read_and_normalize_train_data(img_rows, img_cols, 3)\n\n# loading validation images\n# test_files, test_targets = read_and_normalize_sampled_test_data(nb_test_samples, img_rows, img_cols, 3)","metadata":{"execution":{"iopub.status.busy":"2022-07-08T21:03:10.004728Z","iopub.execute_input":"2022-07-08T21:03:10.005080Z","iopub.status.idle":"2022-07-08T21:04:56.868859Z","shell.execute_reply.started":"2022-07-08T21:03:10.005051Z","shell.execute_reply":"2022-07-08T21:04:56.867833Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"  0%|          | 0/10 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Loading directory c0\n","output_type":"stream"},{"name":"stderr","text":" 10%|█         | 1/10 [00:11<01:43, 11.53s/it]","output_type":"stream"},{"name":"stdout","text":"Loading directory c1\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 2/10 [00:22<01:30, 11.34s/it]","output_type":"stream"},{"name":"stdout","text":"Loading directory c2\n","output_type":"stream"},{"name":"stderr","text":" 30%|███       | 3/10 [00:33<01:17, 11.02s/it]","output_type":"stream"},{"name":"stdout","text":"Loading directory c3\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 4/10 [00:44<01:05, 10.96s/it]","output_type":"stream"},{"name":"stdout","text":"Loading directory c4\n","output_type":"stream"},{"name":"stderr","text":" 50%|█████     | 5/10 [00:55<00:55, 11.16s/it]","output_type":"stream"},{"name":"stdout","text":"Loading directory c5\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 6/10 [01:06<00:43, 10.95s/it]","output_type":"stream"},{"name":"stdout","text":"Loading directory c6\n","output_type":"stream"},{"name":"stderr","text":" 70%|███████   | 7/10 [01:17<00:33, 11.03s/it]","output_type":"stream"},{"name":"stdout","text":"Loading directory c7\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 8/10 [01:27<00:21, 10.69s/it]","output_type":"stream"},{"name":"stdout","text":"Loading directory c8\n","output_type":"stream"},{"name":"stderr","text":" 90%|█████████ | 9/10 [01:36<00:10, 10.12s/it]","output_type":"stream"},{"name":"stdout","text":"Loading directory c9\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [01:46<00:00, 10.65s/it]\n","output_type":"stream"}]},{"cell_type":"code","source":"train_generator = Traindatagen.flow(x_train_vgg, y_train_vgg, batch_size = 256)\nval_generator = Valdatagen.flow(x_test_vgg, y_test_vgg, batch_size = 64)","metadata":{"execution":{"iopub.status.busy":"2022-07-08T21:05:46.120620Z","iopub.execute_input":"2022-07-08T21:05:46.121259Z","iopub.status.idle":"2022-07-08T21:05:47.504995Z","shell.execute_reply.started":"2022-07-08T21:05:46.121225Z","shell.execute_reply":"2022-07-08T21:05:47.504037Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"epochs = 20\ntrain_bs = 256\nvaldi_bs = 64","metadata":{"execution":{"iopub.status.busy":"2022-07-08T20:35:29.532578Z","iopub.execute_input":"2022-07-08T20:35:29.53346Z","iopub.status.idle":"2022-07-08T20:35:29.541994Z","shell.execute_reply.started":"2022-07-08T20:35:29.533429Z","shell.execute_reply":"2022-07-08T20:35:29.539615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def classificationModel():\n    inp = keras.layers.Input(shape=(128, 128, 3))\n    vgg = VGG16(weights='imagenet',\n                  include_top=False,\n                  input_tensor = inp,\n                  input_shape=(128, 128, 3))\n    vgg.trainable = False\n    \n    x = vgg.get_layer('block5_pool').output\n    x = tf.keras.layers.Flatten()(x)\n    # x = tf.keras.layers.GlobalAveragePooling2D()(x)\n    x = keras.layers.Dense(256, activation='relu')(x)\n    output = keras.layers.Dense(10, activation='softmax')(x)\n    \n    model = tf.keras.models.Model(inputs = inp, outputs=output)\n\n    return model\n    ","metadata":{"execution":{"iopub.status.busy":"2022-07-08T21:13:18.733998Z","iopub.execute_input":"2022-07-08T21:13:18.734705Z","iopub.status.idle":"2022-07-08T21:13:18.742083Z","shell.execute_reply.started":"2022-07-08T21:13:18.734671Z","shell.execute_reply":"2022-07-08T21:13:18.741152Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"keras.backend.clear_session()\nmodel = classificationModel()\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T21:13:24.919425Z","iopub.execute_input":"2022-07-08T21:13:24.920335Z","iopub.status.idle":"2022-07-08T21:13:25.203709Z","shell.execute_reply.started":"2022-07-08T21:13:24.920298Z","shell.execute_reply":"2022-07-08T21:13:25.202716Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Model: \"model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 128, 128, 3)]     0         \n_________________________________________________________________\nblock1_conv1 (Conv2D)        (None, 128, 128, 64)      1792      \n_________________________________________________________________\nblock1_conv2 (Conv2D)        (None, 128, 128, 64)      36928     \n_________________________________________________________________\nblock1_pool (MaxPooling2D)   (None, 64, 64, 64)        0         \n_________________________________________________________________\nblock2_conv1 (Conv2D)        (None, 64, 64, 128)       73856     \n_________________________________________________________________\nblock2_conv2 (Conv2D)        (None, 64, 64, 128)       147584    \n_________________________________________________________________\nblock2_pool (MaxPooling2D)   (None, 32, 32, 128)       0         \n_________________________________________________________________\nblock3_conv1 (Conv2D)        (None, 32, 32, 256)       295168    \n_________________________________________________________________\nblock3_conv2 (Conv2D)        (None, 32, 32, 256)       590080    \n_________________________________________________________________\nblock3_conv3 (Conv2D)        (None, 32, 32, 256)       590080    \n_________________________________________________________________\nblock3_pool (MaxPooling2D)   (None, 16, 16, 256)       0         \n_________________________________________________________________\nblock4_conv1 (Conv2D)        (None, 16, 16, 512)       1180160   \n_________________________________________________________________\nblock4_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n_________________________________________________________________\nblock4_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n_________________________________________________________________\nblock4_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n_________________________________________________________________\nblock5_conv1 (Conv2D)        (None, 8, 8, 512)         2359808   \n_________________________________________________________________\nblock5_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n_________________________________________________________________\nblock5_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n_________________________________________________________________\nblock5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n_________________________________________________________________\nflatten (Flatten)            (None, 8192)              0         \n_________________________________________________________________\ndense (Dense)                (None, 256)               2097408   \n_________________________________________________________________\ndense_1 (Dense)              (None, 10)                2570      \n=================================================================\nTotal params: 16,814,666\nTrainable params: 2,099,978\nNon-trainable params: 14,714,688\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"# opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n# model.compile(optimizer='rmsprop',\n#                 loss='categorical_crossentropy',\n#                 metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-07-08T21:13:45.885540Z","iopub.execute_input":"2022-07-08T21:13:45.886145Z","iopub.status.idle":"2022-07-08T21:13:45.899544Z","shell.execute_reply.started":"2022-07-08T21:13:45.886110Z","shell.execute_reply":"2022-07-08T21:13:45.898592Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\nmodel.compile(optimizer=opt,\n                loss='categorical_crossentropy',\n                metrics=['accuracy'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"early_stopping = keras.callbacks.EarlyStopping(\n    monitor='val_loss',\n    min_delta=0.0001,\n    patience=3,\n    verbose=1,\n    mode='min',\n    baseline=None,\n    restore_best_weights=True\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 20\ntrain_bs = 256\nvaldi_bs = 64","metadata":{"execution":{"iopub.status.busy":"2022-07-08T21:13:53.551958Z","iopub.execute_input":"2022-07-08T21:13:53.552335Z","iopub.status.idle":"2022-07-08T21:13:53.557744Z","shell.execute_reply.started":"2022-07-08T21:13:53.552305Z","shell.execute_reply":"2022-07-08T21:13:53.556261Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"## CNN Viualization","metadata":{}},{"cell_type":"code","source":"%%capture\n!pip install wandb","metadata":{"execution":{"iopub.status.busy":"2022-07-08T21:14:09.767943Z","iopub.execute_input":"2022-07-08T21:14:09.768287Z","iopub.status.idle":"2022-07-08T21:14:20.083273Z","shell.execute_reply.started":"2022-07-08T21:14:09.768259Z","shell.execute_reply":"2022-07-08T21:14:20.082097Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"import wandb\nfrom wandb.keras import WandbCallback\n\nwandb.login()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T21:14:34.441940Z","iopub.execute_input":"2022-07-08T21:14:34.442382Z","iopub.status.idle":"2022-07-08T21:15:24.869451Z","shell.execute_reply.started":"2022-07-08T21:14:34.442346Z","shell.execute_reply":"2022-07-08T21:15:24.868508Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"class GradCAM:\n    \"\"\"\n    Reference:\n        https://www.pyimagesearch.com/2020/03/09/grad-cam-visualize-class-activation-maps-with-keras-tensorflow-and-deep-learning/\n    \"\"\"\n\n    def __init__(self, model, layerName):\n        self.model = model\n        self.layerName = layerName\n\n        self.gradModel = tf.keras.models.Model(inputs=[self.model.inputs],\n                                               outputs=[self.model.get_layer(self.layerName).output, self.model.output])\n\n    def compute_heatmap(self, image, classIdx, eps=1e-8):\n        with tf.GradientTape() as tape:\n            tape.watch(self.gradModel.get_layer(self.layerName).variables)\n            inputs = tf.cast(image, tf.float32)\n            (convOutputs, predictions) = self.gradModel(inputs)\n\n            if len(predictions) == 1:\n                # Binary Classification\n                loss = predictions[0]\n            else:\n                loss = predictions[:, classIdx]\n\n        grads = tape.gradient(loss, convOutputs)\n\n        castConvOutputs = tf.cast(convOutputs > 0, \"float32\")\n        castGrads = tf.cast(grads > 0, \"float32\")\n        guidedGrads = castConvOutputs * castGrads * grads\n\n        convOutputs = convOutputs[0]\n        guidedGrads = guidedGrads[0]\n\n        weights = tf.reduce_mean(guidedGrads, axis=(0, 1))\n        cam = tf.reduce_sum(tf.multiply(weights, convOutputs), axis=-1)\n\n        (w, h) = (image.shape[2], image.shape[1])\n        heatmap = cv2.resize(cam.numpy(), (w, h))\n\n        numer = heatmap - np.min(heatmap)\n        denom = (heatmap.max() - heatmap.min()) + eps\n        heatmap = numer / denom\n        heatmap = (heatmap * 255).astype(\"uint8\")\n\n        return heatmap\n\n\n    def overlay_heatmap(self, heatmap, image, alpha=0.5, colormap=cv2.COLORMAP_HOT):\n        heatmap = cv2.applyColorMap(heatmap, colormap)\n        output = cv2.addWeighted(image, alpha, heatmap, 1 - alpha, 0)\n\n        return (heatmap, output)","metadata":{"execution":{"iopub.status.busy":"2022-07-08T21:15:30.588769Z","iopub.execute_input":"2022-07-08T21:15:30.589401Z","iopub.status.idle":"2022-07-08T21:15:30.605892Z","shell.execute_reply.started":"2022-07-08T21:15:30.589365Z","shell.execute_reply":"2022-07-08T21:15:30.604530Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"class GRADCamLogger(tf.keras.callbacks.Callback):\n    def __init__(self, validation_data, layer_name):\n      super(GRADCamLogger, self).__init__()\n      self.validation_data = validation_data\n      self.layer_name = layer_name\n\n    def on_epoch_end(self, logs, epoch):\n      images = []\n      grad_cam = []\n\n      ## Initialize GRADCam Class\n      cam = GradCAM(model, self.layer_name)\n\n      for image in self.validation_data:\n        image = np.expand_dims(image, 0)\n        pred = model.predict(image)\n        classIDx = np.argmax(pred[0])\n  \n        ## Compute Heatmap\n        heatmap = cam.compute_heatmap(image, classIDx)\n        \n        image = image.reshape(image.shape[1:])\n        image = image*255\n        image = image.astype(np.uint8)\n\n        ## Overlay heatmap on original image\n        heatmap = cv2.resize(heatmap, (image.shape[0],image.shape[1]))\n        (heatmap, output) = cam.overlay_heatmap(heatmap, image, alpha=0.5)\n\n        images.append(image)\n        grad_cam.append(output)\n\n      wandb.log({\"images\": [wandb.Image(image)\n                            for image in images]})\n      wandb.log({\"gradcam\": [wandb.Image(cam)\n                            for cam in grad_cam]})","metadata":{"execution":{"iopub.status.busy":"2022-07-08T21:15:38.241706Z","iopub.execute_input":"2022-07-08T21:15:38.242834Z","iopub.status.idle":"2022-07-08T21:15:38.253894Z","shell.execute_reply.started":"2022-07-08T21:15:38.242783Z","shell.execute_reply":"2022-07-08T21:15:38.252500Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"## Prepare sample images to run your GradCam on. \nsample_images, sample_labels = val_generator[20]\nsample_images.shape, sample_labels.shape","metadata":{"execution":{"iopub.status.busy":"2022-07-08T21:15:41.048361Z","iopub.execute_input":"2022-07-08T21:15:41.048733Z","iopub.status.idle":"2022-07-08T21:15:41.071443Z","shell.execute_reply.started":"2022-07-08T21:15:41.048704Z","shell.execute_reply":"2022-07-08T21:15:41.070631Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/keras_preprocessing/image/image_data_generator.py:720: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n  warnings.warn('This ImageDataGenerator specifies '\n/opt/conda/lib/python3.7/site-packages/keras_preprocessing/image/image_data_generator.py:728: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n  warnings.warn('This ImageDataGenerator specifies '\n","output_type":"stream"},{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"((64, 128, 128, 3), (64, 10))"},"metadata":{}}]},{"cell_type":"code","source":"# wandb.init(entity='ayush-thakur', project='interpretability')\nwandb.init(project=\"test\", entity=\"team-7\")","metadata":{"execution":{"iopub.status.busy":"2022-07-08T21:15:45.559855Z","iopub.execute_input":"2022-07-08T21:15:45.560203Z","iopub.status.idle":"2022-07-08T21:15:48.513751Z","shell.execute_reply.started":"2022-07-08T21:15:45.560173Z","shell.execute_reply":"2022-07-08T21:15:48.512622Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mz1z\u001b[0m (\u001b[33mteam-7\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.12.21 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.12.18"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20220708_211545-3czu7ptg</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href=\"https://wandb.ai/team-7/test/runs/3czu7ptg\" target=\"_blank\">floral-puddle-3</a></strong> to <a href=\"https://wandb.ai/team-7/test\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"execution_count":29,"output_type":"execute_result","data":{"text/html":"<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/team-7/test/runs/3czu7ptg?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>","text/plain":"<wandb.sdk.wandb_run.Run at 0x7fa81c3193d0>"},"metadata":{}}]},{"cell_type":"code","source":"# History_Rs = resnetRs.fit(train_generator,\n#          validation_data=val_generator,\n#          steps_per_epoch=len(x_train_rs) // train_bs, epochs=epochs,\n#           validation_steps =len(x_test_rs)//valdi_bs, verbose = 1)\n\n\nhistory = model.fit(train_generator,\n                          validation_data=val_generator,\n                          steps_per_epoch=len(x_train_vgg) // train_bs, \n                          epochs=epochs,\n                          validation_steps =len(x_test_vgg)//valdi_bs, \n                          verbose = 1,\n                          callbacks=[WandbCallback(data_type=\"image\", validation_data=(sample_images, sample_labels)),\n                                     GRADCamLogger(sample_images, layer_name='block5_conv3'),\n                                     early_stopping])\n","metadata":{"execution":{"iopub.status.busy":"2022-07-08T21:47:40.386026Z","iopub.execute_input":"2022-07-08T21:47:40.386404Z","iopub.status.idle":"2022-07-08T22:14:26.307949Z","shell.execute_reply.started":"2022-07-08T21:47:40.386374Z","shell.execute_reply":"2022-07-08T22:14:26.306732Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"Epoch 1/20\n70/70 [==============================] - 71s 1s/step - loss: 0.7821 - accuracy: 0.7400 - val_loss: 0.4331 - val_accuracy: 0.8384\nEpoch 2/20\n70/70 [==============================] - 70s 1s/step - loss: 0.7561 - accuracy: 0.7493 - val_loss: 0.6337 - val_accuracy: 0.7873\nEpoch 3/20\n70/70 [==============================] - 72s 1s/step - loss: 0.7295 - accuracy: 0.7573 - val_loss: 0.5487 - val_accuracy: 0.8016\nEpoch 4/20\n70/70 [==============================] - 70s 1s/step - loss: 0.7366 - accuracy: 0.7501 - val_loss: 0.4736 - val_accuracy: 0.8438\nEpoch 5/20\n70/70 [==============================] - 70s 1s/step - loss: 0.7197 - accuracy: 0.7589 - val_loss: 0.4291 - val_accuracy: 0.8475\nEpoch 6/20\n70/70 [==============================] - 70s 1s/step - loss: 0.7117 - accuracy: 0.7621 - val_loss: 0.4234 - val_accuracy: 0.8469\nEpoch 7/20\n70/70 [==============================] - 70s 1s/step - loss: 0.6835 - accuracy: 0.7694 - val_loss: 0.5421 - val_accuracy: 0.8089\nEpoch 8/20\n70/70 [==============================] - 71s 1s/step - loss: 0.6877 - accuracy: 0.7685 - val_loss: 0.3358 - val_accuracy: 0.8864\nEpoch 9/20\n70/70 [==============================] - 70s 1000ms/step - loss: 0.6854 - accuracy: 0.7703 - val_loss: 0.4301 - val_accuracy: 0.8527\nEpoch 10/20\n70/70 [==============================] - 71s 1s/step - loss: 0.6622 - accuracy: 0.7782 - val_loss: 0.3579 - val_accuracy: 0.8882\nEpoch 11/20\n70/70 [==============================] - 70s 1s/step - loss: 0.6816 - accuracy: 0.7723 - val_loss: 0.3493 - val_accuracy: 0.8853\nEpoch 12/20\n70/70 [==============================] - 71s 1s/step - loss: 0.6350 - accuracy: 0.7875 - val_loss: 0.4482 - val_accuracy: 0.8469\nEpoch 13/20\n70/70 [==============================] - 71s 1s/step - loss: 0.6389 - accuracy: 0.7891 - val_loss: 0.3386 - val_accuracy: 0.8884\nEpoch 14/20\n70/70 [==============================] - 71s 1s/step - loss: 0.6559 - accuracy: 0.7792 - val_loss: 0.3151 - val_accuracy: 0.8996\nEpoch 15/20\n70/70 [==============================] - 73s 1s/step - loss: 0.6189 - accuracy: 0.7916 - val_loss: 0.3106 - val_accuracy: 0.8969\nEpoch 16/20\n70/70 [==============================] - 71s 1s/step - loss: 0.6178 - accuracy: 0.7961 - val_loss: 0.3818 - val_accuracy: 0.8616\nEpoch 17/20\n70/70 [==============================] - 72s 1s/step - loss: 0.6161 - accuracy: 0.7937 - val_loss: 0.3090 - val_accuracy: 0.8929\nEpoch 18/20\n70/70 [==============================] - 70s 1s/step - loss: 0.6126 - accuracy: 0.8019 - val_loss: 0.3099 - val_accuracy: 0.9022\nEpoch 19/20\n70/70 [==============================] - 72s 1s/step - loss: 0.5958 - accuracy: 0.7995 - val_loss: 0.2937 - val_accuracy: 0.9056\nEpoch 20/20\n70/70 [==============================] - 71s 1s/step - loss: 0.6031 - accuracy: 0.7947 - val_loss: 0.3408 - val_accuracy: 0.8779\n","output_type":"stream"}]},{"cell_type":"code","source":"model.save('./vgg_tl_model.h5')","metadata":{"execution":{"iopub.status.busy":"2022-07-08T15:04:17.168053Z","iopub.execute_input":"2022-07-08T15:04:17.168675Z","iopub.status.idle":"2022-07-08T15:04:17.307567Z","shell.execute_reply.started":"2022-07-08T15:04:17.16864Z","shell.execute_reply":"2022-07-08T15:04:17.30657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_model = tf.keras.models.load_model('./my_model.h5')","metadata":{"execution":{"iopub.status.busy":"2022-07-08T15:06:00.280427Z","iopub.execute_input":"2022-07-08T15:06:00.280931Z","iopub.status.idle":"2022-07-08T15:06:00.645273Z","shell.execute_reply.started":"2022-07-08T15:06:00.280886Z","shell.execute_reply":"2022-07-08T15:06:00.644115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc = History_Rs_2.history['accuracy']\nval_acc = History_Rs_2.history['val_accuracy']\nloss = History_Rs_2.history['loss']\nval_loss = History_Rs_2.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\n\nplt.figure()\n\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T14:50:41.49143Z","iopub.execute_input":"2022-07-08T14:50:41.491928Z","iopub.status.idle":"2022-07-08T14:50:41.967945Z","shell.execute_reply.started":"2022-07-08T14:50:41.491885Z","shell.execute_reply":"2022-07-08T14:50:41.967068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}